{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining DataFrames\n",
    "\n",
    "In this notebook, you'll see two different ways to combine _pandas_ DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll import a DataFrame containing information on the revenue and quantity for sales that occurred in the year 2012."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sales_2012 = pd.read_csv('../data/sales_2012.csv')\n",
    "sales_2012.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll bring in a dataset which shows product, retailer, and order method information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "products = pd.read_csv('../data/products.csv')\n",
    "products.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that these two DataFrames can be linked together through the `Sale_ID` column. Let's merge these together so that we can do some further analysis.\n",
    "\n",
    "Recall that the syntax for merging dataframes in pandas is:\n",
    "\n",
    "```pd.merge(left dataframe, right dataframe, how to merge, column to merge on)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_data = pd.merge(products, sales_2012, how = 'right', on = 'Sale_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we have some missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## How many values are we missing from each column?\n",
    "\n",
    "combined_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we have a row with Sale_ID of 3 which seems to be missing all of the product information. Let's double-check that this information is not contained in the products data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "products[products['Sale_ID'] == 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once combined, we can start asking questions of our data.\n",
    "\n",
    "#### Question 1: Which product type generated us the most total revenue in 2012? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Try and fill in the code to answer this question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2: What was our highest volume product?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_data.groupby('Product')['Quantity'].sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is Zone?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_data.loc[combined_data['Product'] == 'Zone']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3: For which retailer type do we have the highest sales quantity of Zone?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_data.loc[combined_data['Product'] == 'Zone'].groupby('Retailer_type')['Quantity'].sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenating DataFrames\n",
    "\n",
    "Notice that we also have access to sales data for 2013. Let's read it in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sales_2013 = pd.read_csv('../data/sales_2013.csv')\n",
    "sales_2013.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data looks to be formatted in the same way as our 2012 sales data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sales_2012.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to combine these two DataFrames. In this case, we don't want to merge, as each record should still have its own row in the result. Instead, this is a time when we want to **concatenate**. \n",
    "\n",
    "To concatenate DataFrames, we can pass the dataframes that we want to combine as a list into the `pd.concat` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.concat([sales_2012, sales_2013])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that while we have 66840 rows, the index value at the end of the DataFrame is only 32944. We can reindex the result by using the `ignore_index` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.concat([sales_2012, sales_2013], ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've also got sales for 2014. Let's see how we could read all three in and concatenate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sales_dfs = []\n",
    "\n",
    "sales_2012 = pd.read_csv('../data/sales_2012.csv')\n",
    "sales_dfs.append(sales_2012)\n",
    "\n",
    "sales_2013 = pd.read_csv('../data/sales_2013.csv')\n",
    "sales_dfs.append(sales_2013)\n",
    "\n",
    "sales_2014 = pd.read_csv('../data/sales_2014.csv')\n",
    "sales_dfs.append(sales_2014)\n",
    "\n",
    "sales = pd.concat(sales_dfs,\n",
    "                 ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the above code accomplishes what we want, perhaps there is a better way to write it.\n",
    "\n",
    "Notice that we are reusing the same pattern of code three times:\n",
    "\n",
    "```\n",
    "sales_2012 = pd.read_csv('../data/sales_2012.csv')\n",
    "sales_dfs.append(sales_2012)\n",
    "```\n",
    "\n",
    "This is the basic pattern:\n",
    "```\n",
    "df = pd.read_csv(filepath)\n",
    "sales_dfs.append(df)\n",
    "```\n",
    "\n",
    "This can be used in a **for loop**, which is a way to direct Python to do the same thing multiple times.\n",
    "\n",
    "A for loop needs two things:\n",
    "1. a collection to iterate over\n",
    "2. directions about what to do for each item in that collection\n",
    "\n",
    "Here, the collection is the list of filepaths, and the directions are the basic pattern above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Start with an empty list to hold the individual DataFrames\n",
    "sales_dfs = []\n",
    "\n",
    "for filename in ['../data/sales_2012.csv',\n",
    "                 '../data/sales_2013.csv',\n",
    "                 '../data/sales_2014.csv']:\n",
    "    df = pd.read_csv(filename)\n",
    "    sales_dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sales = pd.concat(sales_dfs, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll look at a lot more examples of for loops in the next notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
